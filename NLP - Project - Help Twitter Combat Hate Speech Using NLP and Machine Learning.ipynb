{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Help Twitter Combat Hate Speech Using NLP and Machine Learning\n",
    "\n",
    "Twitter is the biggest platform where anybody and everybody can have their views heard. Some of these voices spread hate and negativity. Twitter is wary of its platform being used as a medium  to spread hate.\n",
    "\n",
    "Task here is to identify the hate tweets, using NLP techniques. \n",
    "\n",
    "###### Analysis to be done:\n",
    "\n",
    "* Clean up tweets.\n",
    "* Build a classification model, use NLP. \n",
    "* Cleanup specific for tweets data. \n",
    "* Regularization and hyperparameter tuning using stratified k-fold.\n",
    "* Cross validation.\n",
    "\n",
    "\n",
    "Content: \n",
    "\n",
    "* id: identifier number of the tweet\n",
    "* Label: 0 (non-hate) /1 (hate)\n",
    "* Tweet: the text in the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the tweets file using read_csv function from Pandas package.\n",
    "\n",
    "dt_tweets = pd.read_csv(\"TwitterHate.csv\")\n",
    "dt_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.value_counts of 0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "31957    0\n",
       "31958    0\n",
       "31959    0\n",
       "31960    1\n",
       "31961    0\n",
       "Name: label, Length: 31962, dtype: int64>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distribution level 1 or 0\n",
    "\n",
    "dt_tweets.label.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.929854\n",
       "1    0.070146\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_tweets.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly all of data is leveled as 0 (non-hate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         @user when a father is dysfunctional and is s...\n",
      "1        @user @user thanks for #lyft credit i can't us...\n",
      "2                                      bihday your majesty\n",
      "3        #model   i love u take with u all the time in ...\n",
      "4                   factsguide: society now    #motivation\n",
      "                               ...                        \n",
      "31957    ate @user isz that youuu?ðððððð...\n",
      "31958      to see nina turner on the airwaves trying to...\n",
      "31959    listening to sad songs on a monday morning otw...\n",
      "31960    @user #sikh #temple vandalised in in #calgary,...\n",
      "31961                     thank you @user for you follow  \n",
      "Name: tweet, Length: 31962, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(dt_tweets.tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = dt_tweets.tweet.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run'\n",
      " \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\"\n",
      " '  bihday your majesty' ...\n",
      " 'listening to sad songs on a monday morning otw to work is sad  '\n",
      " '@user #sikh #temple vandalised in in #calgary, #wso condemns  act  '\n",
      " 'thank you @user for you follow  ']\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### cleanup in below 7 steps: \n",
    "\n",
    "* Normalize the case.\n",
    "* Using regular expressions, remove user handles that begins with '@’.\n",
    "* Using regular expressions, remove URLs.\n",
    "* Using TweetTokenizer from NLTK, tokenize the tweets into individual terms.\n",
    "* Remove stop words.\n",
    "* Remove redundant terms like ‘amp’, ‘rt’, etc.\n",
    "* Remove ‘#’ symbols from the tweet while retaining the term.\n",
    "* Remove terms with a length of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Normalize the case.\n",
    "\n",
    "tweets_lower = [twt.lower() for twt in tweets0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' course rocks! http://johndoe.com/mk'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Using regular expressions, remove user handles that begins with '@’. First test regular expression on sample tweet.\n",
    "\n",
    "re.sub(\"@\\w+\",\"\", \"@NLP course rocks! http://johndoe.com/mk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply regular expression tweeter handles over the whole tweet.\n",
    "\n",
    "tweets_nouser = [re.sub(\"@\\w+\",\"\", twt) for twt in tweets_lower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@John this course rocks! '"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Test regular expression to remove URL:\n",
    "\n",
    "re.sub(\"\\w+://\\S+\",\"\", \"@John this course rocks! http://johndoe.com/mk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove URL in all tweets.\n",
    "tweets_nourl = [re.sub(\"\\w+://\\S+\",\"\", twt) for twt in tweets_nouser]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['when', 'a', 'father', 'is', 'dysfunctional', 'and', 'is', 'so', 'selfish', 'he', 'drags', 'his', 'kids', 'into', 'his', 'dysfunction', '.', '#run']\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Using TweetTokenizer from NLTK, tokenize the tweets into individual terms.\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tkn = TweetTokenizer()\n",
    "\n",
    "tweet_token = [tkn.tokenize(sent) for sent in tweets_nourl]\n",
    "print(tweet_token[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Remove stop word\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stop_nltk = stopwords.words(\"english\")\n",
    "stop_punct = list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Remove redundant terms like ‘amp’, ‘rt’, etc.\n",
    "\n",
    "# Adding some specific punctuation from the data:\n",
    "stop_punct.extend(['...','``',\"''\",\"..\"])\n",
    "stop_context = ['rt', 'amp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['father', 'dysfunctional', 'selfish', 'drags', 'kids', 'dysfunction', 'run']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 7 & 8: Remove stop words from a single tokenized sentence, Remove # tags, Remove terms with length = 1\n",
    "# sum up stop_nltk, stop_punct, stop_context from steps 5 & 6\n",
    "\n",
    "stop_final = stop_nltk + stop_punct + stop_context\n",
    "\n",
    "def del_stop(sent):\n",
    "    return [re.sub(\"#\",\"\",term) for term in sent if ((term not in stop_final) & (len(term)>1))]\n",
    "tweets_clean = [del_stop(tweet) for tweet in tweet_token]\n",
    "\n",
    "tweets_clean = [del_stop(tweet) for tweet in tweet_token]\n",
    "tweets_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding all terms to one big list.\n",
    "\n",
    "term_list = []\n",
    "for tweet in tweets_clean:\n",
    "    term_list.extend(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 2748),\n",
       " ('day', 2276),\n",
       " ('happy', 1684),\n",
       " ('time', 1131),\n",
       " ('life', 1118),\n",
       " ('like', 1047),\n",
       " (\"i'm\", 1018),\n",
       " ('today', 1013),\n",
       " ('new', 994),\n",
       " ('thankful', 946)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use counter and find the 10 most common terms.\n",
    "\n",
    "from collections import Counter\n",
    "res = Counter(term_list)\n",
    "res.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the tokens back to form strings.  This will be required for the vectorizers.\n",
    "\n",
    "tweets_clean = [\" \".join(tweet) for tweet in tweets_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and label.\n",
    "\n",
    "X = tweets_clean\n",
    "y = inp_tweets0.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split test and train\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22373, 5000), (9589, 5000))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use TF-IDF  values for the terms as feature to get into a vector space model. \n",
    "# Instantiate with a maximum of 5000 terms in your vocabulary.\n",
    "# Fit the model.\n",
    "# Apply to train set.\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 5000)\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "X_train_bow.shape, X_test_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model building: Ordinary Logistic Regression\n",
    "* Instantiate LogisticRegression from sklearn with default parameters.\n",
    "* Fit on the train data.\n",
    "* Make predictions for the train and the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_bow, y_train)\n",
    "\n",
    "y_train_pred = logreg.predict(X_train_bow)\n",
    "y_test_pred = logreg.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation: Accuracy, recall, and f1_score\n",
    "* Report the accuracy on the train set.\n",
    "* Report the recall on the train set:decent, high, or low?\n",
    "* Get the f1_score on the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9560184150538595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     20815\n",
      "           1       0.96      0.39      0.55      1558\n",
      "\n",
      "    accuracy                           0.96     22373\n",
      "   macro avg       0.96      0.69      0.76     22373\n",
      "weighted avg       0.96      0.96      0.95     22373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "scr1 = accuracy_score(y_train, y_train_pred)\n",
    "print(scr1)\n",
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f1 score is 95.6%. Due to heavy class imbalance (0 -> 0.929854 and 1 -> 0.070146, this accuracy may not be good if we are not capturing the 1s well at all.\n",
    "\n",
    "So let’s look at the classification report: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     20815\n",
      "           1       0.96      0.39      0.55      1558\n",
      "\n",
      "    accuracy                           0.96     22373\n",
      "   macro avg       0.96      0.69      0.76     22373\n",
      "weighted avg       0.96      0.96      0.95     22373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall is just 39% for 1 class which is not so great at all. Need to adjust the class imbalance, as model is more onto the 0s. Adjust in Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiating with the right parameter.\n",
    "\n",
    "# Train again with the adjustment and evaluate.\n",
    "# 1. Train the model on the train set.\n",
    "# 2. Evaluate the predictions on the train set: accuracy, recall, and f1_score.\n",
    "\n",
    "logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "logreg.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9535153980244044"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the train set:\n",
    "y_train_pred = logreg.predict(X_train_bow)\n",
    "accuracy_score(y_train, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score is 95.35%.  It is a little lower than the previous model, but the classification report will give better details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97     20815\n",
      "           1       0.60      0.97      0.74      1558\n",
      "\n",
      "    accuracy                           0.95     22373\n",
      "   macro avg       0.80      0.96      0.86     22373\n",
      "weighted avg       0.97      0.95      0.96     22373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here Recall is 97% for class 1s ! Improved a lot. The f1_score is also better at 0.74. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularization and Hyperparameter tuning:\n",
    "* Import GridSearch and StratifiedKFold because of class imbalance.\n",
    "* Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters.\n",
    "* Use a balanced class weight while instantiating the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search. \n",
    "\n",
    "param_grid = {\n",
    "    'C': [0.01,0.1,1,10,100],\n",
    "    'penalty': [\"l1\",\"l2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the logistic regression model with a balanced class weight.\n",
    "\n",
    "classifier_lr = LogisticRegression(class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the parameters with the best recall in cross validation.\n",
    "* Choose ‘recall’ as the metric for scoring.\n",
    "* Choose stratified 4 fold cross validation scheme.\n",
    "* Fit it on the train set.\n",
    "\n",
    "You’ll supply stratified k-fold as out cv strategy to GridSearchCV. You need to stratify as there is heavy class imbalance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator = classifier_lr, param_grid = param_grid, \n",
    "                          cv = StratifiedKFold(4), n_jobs = -1, verbose = 1, scoring = \"recall\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 10 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    3.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=4, random_state=None, shuffle=False),\n",
       "             estimator=LogisticRegression(class_weight='balanced'), n_jobs=-1,\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             scoring='recall', verbose=1)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting on the train data to get the best parameters:\n",
    "grid_search.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From cross validation, the best parameters are: C = 1, penalty = “l2”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and evaluate using the best estimator.\n",
    "* Use the best estimator from the grid search to make predictions on the test set.\n",
    "* What is the recall on the test set for the toxic comments?\n",
    "* What is the f1_score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      8905\n",
      "           1       0.49      0.77      0.60       684\n",
      "\n",
      "    accuracy                           0.93      9589\n",
      "   macro avg       0.73      0.85      0.78      9589\n",
      "weighted avg       0.95      0.93      0.93      9589\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = grid_search.best_estimator_.predict(X_test_bow)\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1_score for 1 class is 0.60 and the recall is 0.77. Great!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
